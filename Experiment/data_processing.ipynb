{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of    Customer_ID                 Asset_Types            Investment_Amounts  \\\n",
       "0   Customer_1         Bonds, Gold, Stocks  46693.31, 40330.82, 17836.22   \n",
       "1   Customer_2  Stocks, Real Estate, Bonds  18351.85, 48591.92, 31063.11   \n",
       "2   Customer_3                Gold, Crypto            46372.42, 28900.68   \n",
       "3   Customer_4  Stocks, Real Estate, Bonds    8083.46, 8058.24, 43781.86   \n",
       "4   Customer_5       Bonds, Stocks, Crypto  34581.79, 30435.21, 19236.64   \n",
       "5   Customer_6         Bonds, Gold, Stocks  22810.36, 35226.06, 18499.87   \n",
       "6   Customer_7                      Stocks                      29193.55   \n",
       "7   Customer_8                 Real Estate                      44638.89   \n",
       "8   Customer_9                 Real Estate                      12098.61   \n",
       "9  Customer_10                 Real Estate                       32525.5   \n",
       "\n",
       "                Current_Values                     Investment_Date  \n",
       "0   35567.26, 44512.46, 223.29  2023-11-27, 2024-02-05, 2024-05-23  \n",
       "1    694.05, 8144.09, 37129.77  2023-01-15, 2020-05-04, 2024-03-11  \n",
       "2            9406.13, 96726.23              2020-04-26, 2022-11-06  \n",
       "3    160.8, 37698.55, 39065.98  2022-04-06, 2020-09-02, 2024-12-28  \n",
       "4  44390.55, 416.525, 96726.23  2021-06-18, 2021-02-22, 2023-10-03  \n",
       "5    5512.35, 39163.76, 498.24  2021-10-09, 2024-03-19, 2020-05-28  \n",
       "6                       109.61                          2022-11-02  \n",
       "7                     18435.64                          2024-12-05  \n",
       "8                     34876.99                          2024-09-03  \n",
       "9                      40968.7                          2024-07-10  >"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First one for tableau data\n",
    "df = pd.read_csv(r'c:\\Jalpa\\Data Science UOT\\Case Studies\\Investment_portfolio\\Cust_Invest_data.csv')\n",
    "\n",
    "#This is for Feature Engineering and Predictive modeling\n",
    "#df = pd.read_csv(r'c:\\Jalpa\\Data Science UOT\\Case Studies\\Investment_portfolio\\Investment_portfolio_analysis\\Data\\100Cust_Invest_data.csv')\n",
    "\n",
    "#df = pd.read_csv('Cust_Invest_data.csv')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, need to separate each row in df so that each asset type gets its own row instead of being combined in a single row per customer. This can be achieve by exploding the multi-asset columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Customer_ID  Asset_Types  Investment_Amounts  Current_Values  \\\n",
      "0    Customer_1        Bonds            46693.31       35567.260   \n",
      "1    Customer_1         Gold            40330.82       44512.460   \n",
      "2    Customer_1       Stocks            17836.22         223.290   \n",
      "3    Customer_2       Stocks            18351.85         694.050   \n",
      "4    Customer_2  Real Estate            48591.92        8144.090   \n",
      "5    Customer_2        Bonds            31063.11       37129.770   \n",
      "6    Customer_3         Gold            46372.42        9406.130   \n",
      "7    Customer_3       Crypto            28900.68       96726.230   \n",
      "8    Customer_4       Stocks             8083.46         160.800   \n",
      "9    Customer_4  Real Estate             8058.24       37698.550   \n",
      "10   Customer_4        Bonds            43781.86       39065.980   \n",
      "11   Customer_5        Bonds            34581.79       44390.550   \n",
      "12   Customer_5       Stocks            30435.21         416.525   \n",
      "13   Customer_5       Crypto            19236.64       96726.230   \n",
      "14   Customer_6        Bonds            22810.36        5512.350   \n",
      "15   Customer_6         Gold            35226.06       39163.760   \n",
      "16   Customer_6       Stocks            18499.87         498.240   \n",
      "17   Customer_7       Stocks            29193.55         109.610   \n",
      "18   Customer_8  Real Estate            44638.89       18435.640   \n",
      "19   Customer_9  Real Estate            12098.61       34876.990   \n",
      "20  Customer_10  Real Estate            32525.50       40968.700   \n",
      "\n",
      "   Investment_Date  \n",
      "0       2023-11-27  \n",
      "1       2024-02-05  \n",
      "2       2024-05-23  \n",
      "3       2023-01-15  \n",
      "4       2020-05-04  \n",
      "5       2024-03-11  \n",
      "6       2020-04-26  \n",
      "7       2022-11-06  \n",
      "8       2022-04-06  \n",
      "9       2020-09-02  \n",
      "10      2024-12-28  \n",
      "11      2021-06-18  \n",
      "12      2021-02-22  \n",
      "13      2023-10-03  \n",
      "14      2021-10-09  \n",
      "15      2024-03-19  \n",
      "16      2020-05-28  \n",
      "17      2022-11-02  \n",
      "18      2024-12-05  \n",
      "19      2024-09-03  \n",
      "20      2024-07-10  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to split and explode multi-asset data\n",
    "def separate_assets(df):\n",
    "    df_expanded = df.copy()\n",
    "    \n",
    "    # Split columns with multiple values into lists\n",
    "    df_expanded[\"Asset_Types\"] = df_expanded[\"Asset_Types\"].str.split(\", \")\n",
    "    df_expanded[\"Investment_Amounts\"] = df_expanded[\"Investment_Amounts\"].str.split(\", \")\n",
    "    df_expanded[\"Current_Values\"] = df_expanded[\"Current_Values\"].str.split(\", \")\n",
    "    df_expanded[\"Investment_Date\"] = df_expanded[\"Investment_Date\"].str.split(\", \")\n",
    "    \n",
    "    # Explode the DataFrame to create separate rows per asset type\n",
    "    df_expanded = df_expanded.explode([\"Asset_Types\", \"Investment_Amounts\", \"Current_Values\", \"Investment_Date\"])\n",
    "\n",
    "    # Convert Investment_Amounts and Current_Values to float\n",
    "    df_expanded[\"Investment_Amounts\"] = df_expanded[\"Investment_Amounts\"].astype(float)\n",
    "    df_expanded[\"Current_Values\"] = df_expanded[\"Current_Values\"].astype(float)\n",
    "    # Convert date column\n",
    "    df_expanded[\"Investment_Date\"] = pd.to_datetime(df_expanded[\"Investment_Date\"], errors=\"coerce\")\n",
    "\n",
    "    \n",
    "    return df_expanded.reset_index(drop=True)\n",
    "\n",
    "# Apply transformation\n",
    "df_separated = separate_assets(df)\n",
    "print(df_separated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Customer_ID         21 non-null     object        \n",
      " 1   Asset_Types         21 non-null     object        \n",
      " 2   Investment_Amounts  21 non-null     float64       \n",
      " 3   Current_Values      21 non-null     float64       \n",
      " 4   Investment_Date     21 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), object(2)\n",
      "memory usage: 968.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_separated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer_ID', 'Asset_Types', 'Investment_Amounts', 'Current_Values',\n",
       "       'Investment_Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_separated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Investment_Amounts</th>\n",
       "      <th>Current_Values</th>\n",
       "      <th>Investment_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29395.731905</td>\n",
       "      <td>28115.581190</td>\n",
       "      <td>2022-11-22 19:25:42.857142784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8058.240000</td>\n",
       "      <td>109.610000</td>\n",
       "      <td>2020-04-26 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18499.870000</td>\n",
       "      <td>694.050000</td>\n",
       "      <td>2021-06-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30435.210000</td>\n",
       "      <td>34876.990000</td>\n",
       "      <td>2023-01-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40330.820000</td>\n",
       "      <td>39163.760000</td>\n",
       "      <td>2024-03-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48591.920000</td>\n",
       "      <td>96726.230000</td>\n",
       "      <td>2024-12-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12882.554325</td>\n",
       "      <td>28817.767785</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Investment_Amounts  Current_Values                Investment_Date\n",
       "count           21.000000       21.000000                             21\n",
       "mean         29395.731905    28115.581190  2022-11-22 19:25:42.857142784\n",
       "min           8058.240000      109.610000            2020-04-26 00:00:00\n",
       "25%          18499.870000      694.050000            2021-06-18 00:00:00\n",
       "50%          30435.210000    34876.990000            2023-01-15 00:00:00\n",
       "75%          40330.820000    39163.760000            2024-03-19 00:00:00\n",
       "max          48591.920000    96726.230000            2024-12-28 00:00:00\n",
       "std          12882.554325    28817.767785                            NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_separated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=df_separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "# import os\n",
    "# path= os.getcwd()\n",
    "\n",
    "df_separated.to_csv(\"TableauData.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting tabpy\n",
      "  Downloading tabpy-2.13.0.tar.gz (466 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (3.0.0)\n",
      "Collecting configparser (from tabpy)\n",
      "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting coverage (from tabpy)\n",
      "  Downloading coverage-7.6.12-cp39-cp39-win_amd64.whl.metadata (8.7 kB)\n",
      "Collecting coveralls (from tabpy)\n",
      "  Downloading coveralls-4.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: docopt in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (0.6.2)\n",
      "Requirement already satisfied: future in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (1.0.0)\n",
      "Collecting genson (from tabpy)\n",
      "  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting hypothesis (from tabpy)\n",
      "  Downloading hypothesis-6.126.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (4.23.0)\n",
      "Collecting mock (from tabpy)\n",
      "  Downloading mock-5.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting nltk (from tabpy)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (2.2.2)\n",
      "Requirement already satisfied: pyopenssl in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (23.2.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (8.3.2)\n",
      "Collecting pytest-cov (from tabpy)\n",
      "  Downloading pytest_cov-6.0.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (2.32.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (1.11.4)\n",
      "Collecting simplejson (from tabpy)\n",
      "  Downloading simplejson-3.20.1-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (1.5.1)\n",
      "Collecting textblob (from tabpy)\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: tornado in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (6.4.1)\n",
      "Collecting twisted (from tabpy)\n",
      "  Downloading twisted-24.11.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (2.2.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from tabpy) (11.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from requests->tabpy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from requests->tabpy) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from requests->tabpy) (2024.8.30)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from hypothesis->tabpy) (24.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from hypothesis->tabpy) (1.2.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from hypothesis->tabpy) (2.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from jsonschema->tabpy) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from jsonschema->tabpy) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from jsonschema->tabpy) (0.20.0)\n",
      "Requirement already satisfied: click in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from nltk->tabpy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from nltk->tabpy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from nltk->tabpy) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from nltk->tabpy) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pandas->tabpy) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pandas->tabpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pandas->tabpy) (2024.1)\n",
      "Requirement already satisfied: cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pyopenssl->tabpy) (39.0.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pytest->tabpy) (2.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pytest->tabpy) (24.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pytest->tabpy) (1.5.0)\n",
      "Requirement already satisfied: tomli>=1 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pytest->tabpy) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pytest->tabpy) (0.4.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from scikit-learn->tabpy) (3.5.0)\n",
      "Collecting automat>=24.8.0 (from twisted->tabpy)\n",
      "  Downloading Automat-24.8.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting constantly>=15.1 (from twisted->tabpy)\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from twisted->tabpy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting incremental>=24.7.0 (from twisted->tabpy)\n",
      "  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from twisted->tabpy) (4.12.2)\n",
      "Collecting zope-interface>=5 (from twisted->tabpy)\n",
      "  Downloading zope.interface-7.2-cp39-cp39-win_amd64.whl.metadata (45 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl->tabpy) (1.17.0)\n",
      "Requirement already satisfied: setuptools>=61.0 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from incremental>=24.7.0->twisted->tabpy) (72.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->tabpy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jalpazenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from cffi>=1.12->cryptography!=40.0.0,!=40.0.1,<42,>=38.0.0->pyopenssl->tabpy) (2.22)\n",
      "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading coverage-7.6.12-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Downloading coveralls-4.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading genson-1.3.0-py3-none-any.whl (21 kB)\n",
      "Downloading hypothesis-6.126.0-py3-none-any.whl (483 kB)\n",
      "Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 1.0/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 893.8 kB/s eta 0:00:00\n",
      "Downloading pytest_cov-6.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading simplejson-3.20.1-cp39-cp39-win_amd64.whl (75 kB)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 524.3/624.3 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading twisted-24.11.0-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.0/3.2 MB 7.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.2 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.6/3.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading Automat-24.8.1-py3-none-any.whl (42 kB)\n",
      "Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Downloading incremental-24.7.2-py3-none-any.whl (20 kB)\n",
      "Downloading zope.interface-7.2-cp39-cp39-win_amd64.whl (211 kB)\n",
      "Building wheels for collected packages: tabpy\n",
      "  Building wheel for tabpy (setup.py): started\n",
      "  Building wheel for tabpy (setup.py): finished with status 'done'\n",
      "  Created wheel for tabpy: filename=tabpy-2.13.0-py2.py3-none-any.whl size=122654 sha256=76b18a97c80d4e63efb1ce404d42119568b0b4d2e68ae4e25fc0839a451d3fe5\n",
      "  Stored in directory: c:\\users\\jalpazenisha\\appdata\\local\\pip\\cache\\wheels\\fa\\7c\\2a\\ec10d8f59473d2760ac251bc0a3196045b68a0ba3a8adbb964\n",
      "Successfully built tabpy\n",
      "Installing collected packages: genson, zope-interface, simplejson, mock, incremental, hypothesis, hyperlink, coverage, constantly, configparser, automat, twisted, nltk, textblob, pytest-cov, coveralls, tabpy\n",
      "Successfully installed automat-24.8.1 configparser-7.1.0 constantly-23.10.4 coverage-7.6.12 coveralls-4.0.1 genson-1.3.0 hyperlink-21.0.0 hypothesis-6.126.0 incremental-24.7.2 mock-5.1.0 nltk-3.9.1 pytest-cov-6.0.0 simplejson-3.20.1 tabpy-2.13.0 textblob-0.19.0 twisted-24.11.0 zope-interface-7.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tabpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new= pd.read_csv()\n",
    "df_new = pd.read_csv(r'c:\\Jalpa\\Data Science UOT\\Case Studies\\Investment_portfolio\\TableauData.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Asset_Types</th>\n",
       "      <th>Investment_Amounts</th>\n",
       "      <th>Current_Values</th>\n",
       "      <th>Investment_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer_1</td>\n",
       "      <td>Bonds</td>\n",
       "      <td>46693.31</td>\n",
       "      <td>35567.260</td>\n",
       "      <td>2023-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer_1</td>\n",
       "      <td>Gold</td>\n",
       "      <td>40330.82</td>\n",
       "      <td>44512.460</td>\n",
       "      <td>2024-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer_1</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>17836.22</td>\n",
       "      <td>223.290</td>\n",
       "      <td>2024-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer_2</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>18351.85</td>\n",
       "      <td>694.050</td>\n",
       "      <td>2023-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer_2</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>48591.92</td>\n",
       "      <td>8144.090</td>\n",
       "      <td>2020-05-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer_2</td>\n",
       "      <td>Bonds</td>\n",
       "      <td>31063.11</td>\n",
       "      <td>37129.770</td>\n",
       "      <td>2024-03-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Customer_3</td>\n",
       "      <td>Gold</td>\n",
       "      <td>46372.42</td>\n",
       "      <td>9406.130</td>\n",
       "      <td>2020-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Customer_3</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>28900.68</td>\n",
       "      <td>96726.230</td>\n",
       "      <td>2022-11-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Customer_4</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>8083.46</td>\n",
       "      <td>160.800</td>\n",
       "      <td>2022-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Customer_4</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>8058.24</td>\n",
       "      <td>37698.550</td>\n",
       "      <td>2020-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Customer_4</td>\n",
       "      <td>Bonds</td>\n",
       "      <td>43781.86</td>\n",
       "      <td>39065.980</td>\n",
       "      <td>2024-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Customer_5</td>\n",
       "      <td>Bonds</td>\n",
       "      <td>34581.79</td>\n",
       "      <td>44390.550</td>\n",
       "      <td>2021-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Customer_5</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>30435.21</td>\n",
       "      <td>416.525</td>\n",
       "      <td>2021-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Customer_5</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>19236.64</td>\n",
       "      <td>96726.230</td>\n",
       "      <td>2023-10-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Customer_6</td>\n",
       "      <td>Bonds</td>\n",
       "      <td>22810.36</td>\n",
       "      <td>5512.350</td>\n",
       "      <td>2021-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Customer_6</td>\n",
       "      <td>Gold</td>\n",
       "      <td>35226.06</td>\n",
       "      <td>39163.760</td>\n",
       "      <td>2024-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Customer_6</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>18499.87</td>\n",
       "      <td>498.240</td>\n",
       "      <td>2020-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Customer_7</td>\n",
       "      <td>Stocks</td>\n",
       "      <td>29193.55</td>\n",
       "      <td>109.610</td>\n",
       "      <td>2022-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Customer_8</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>44638.89</td>\n",
       "      <td>18435.640</td>\n",
       "      <td>2024-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Customer_9</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>12098.61</td>\n",
       "      <td>34876.990</td>\n",
       "      <td>2024-09-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Customer_10</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>32525.50</td>\n",
       "      <td>40968.700</td>\n",
       "      <td>2024-07-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Customer_ID  Asset_Types  Investment_Amounts  Current_Values  \\\n",
       "0    Customer_1        Bonds            46693.31       35567.260   \n",
       "1    Customer_1         Gold            40330.82       44512.460   \n",
       "2    Customer_1       Stocks            17836.22         223.290   \n",
       "3    Customer_2       Stocks            18351.85         694.050   \n",
       "4    Customer_2  Real Estate            48591.92        8144.090   \n",
       "5    Customer_2        Bonds            31063.11       37129.770   \n",
       "6    Customer_3         Gold            46372.42        9406.130   \n",
       "7    Customer_3       Crypto            28900.68       96726.230   \n",
       "8    Customer_4       Stocks             8083.46         160.800   \n",
       "9    Customer_4  Real Estate             8058.24       37698.550   \n",
       "10   Customer_4        Bonds            43781.86       39065.980   \n",
       "11   Customer_5        Bonds            34581.79       44390.550   \n",
       "12   Customer_5       Stocks            30435.21         416.525   \n",
       "13   Customer_5       Crypto            19236.64       96726.230   \n",
       "14   Customer_6        Bonds            22810.36        5512.350   \n",
       "15   Customer_6         Gold            35226.06       39163.760   \n",
       "16   Customer_6       Stocks            18499.87         498.240   \n",
       "17   Customer_7       Stocks            29193.55         109.610   \n",
       "18   Customer_8  Real Estate            44638.89       18435.640   \n",
       "19   Customer_9  Real Estate            12098.61       34876.990   \n",
       "20  Customer_10  Real Estate            32525.50       40968.700   \n",
       "\n",
       "   Investment_Date  \n",
       "0       2023-11-27  \n",
       "1       2024-02-05  \n",
       "2       2024-05-23  \n",
       "3       2023-01-15  \n",
       "4       2020-05-04  \n",
       "5       2024-03-11  \n",
       "6       2020-04-26  \n",
       "7       2022-11-06  \n",
       "8       2022-04-06  \n",
       "9       2020-09-02  \n",
       "10      2024-12-28  \n",
       "11      2021-06-18  \n",
       "12      2021-02-22  \n",
       "13      2023-10-03  \n",
       "14      2021-10-09  \n",
       "15      2024-03-19  \n",
       "16      2020-05-28  \n",
       "17      2022-11-02  \n",
       "18      2024-12-05  \n",
       "19      2024-09-03  \n",
       "20      2024-07-10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"Investment_Date\"] = pd.to_datetime(df_new[\"Investment_Date\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "We can create new features such as:\n",
    "\n",
    "ROI (%) = (Current_Values - Investment_Amounts) / Investment_Amounts * 100\n",
    "Time-based features (e.g., Year, Month, Quarter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID  Asset_Types  Investment_Amounts  Current_Values  \\\n",
      "0  Customer_1        Bonds            46693.31        35567.26   \n",
      "1  Customer_1         Gold            40330.82        44512.46   \n",
      "2  Customer_1       Stocks            17836.22          223.29   \n",
      "3  Customer_2       Stocks            18351.85          694.05   \n",
      "4  Customer_2  Real Estate            48591.92         8144.09   \n",
      "\n",
      "  Investment_Date    ROI (%)  Year  Month  Quarter  \n",
      "0      2023-11-27 -23.827932  2023     11        4  \n",
      "1      2024-02-05  10.368349  2024      2        1  \n",
      "2      2024-05-23 -98.748109  2024      5        2  \n",
      "3      2023-01-15 -96.218092  2023      1        1  \n",
      "4      2020-05-04 -83.239827  2020      5        2  \n"
     ]
    }
   ],
   "source": [
    "# Calculate ROI\n",
    "df_new[\"ROI (%)\"] = (df_new[\"Current_Values\"] - df_new[\"Investment_Amounts\"]) / df_new[\"Investment_Amounts\"] * 100\n",
    "\n",
    "# Extract time-based features\n",
    "df_new[\"Year\"] = df_new[\"Investment_Date\"].dt.year\n",
    "df_new[\"Month\"] = df_new[\"Investment_Date\"].dt.month\n",
    "df_new[\"Quarter\"] = df_new[\"Investment_Date\"].dt.quarter\n",
    "\n",
    "print(df_new.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Prediction Goal \n",
    "\n",
    "Future Investment Value (Regression Problem)\n",
    "Whether an investment will be Profitable or Not (Classification Problem)\n",
    "\n",
    "Let's proceed with predicting Future Investment Value based on past data.\n",
    "\n",
    "Train a Machine Learning Model\n",
    "\n",
    "# Linear Regression model\n",
    "Linear Regression for predicting Current_Values based on investment amount, asset type, and time-based features.\n",
    "\n",
    "Evaluation Metrics for Regression\n",
    "Since we trained a Linear Regression model to predict Current_Values, the key metrics to evaluate it are:\n",
    "\n",
    "Mean Absolute Error (MAE): Measures the average absolute errors: Average absolute difference between actual and predicted values. Lower is better.\n",
    "\n",
    "Mean Squared Error (MSE): Measures the average squared errors: Similar to MAE but penalizes large errors more heavily. Lower is better.\n",
    "\n",
    "R² Score (Coefficient of Determination): Measures how well the model explains variance in the target variable. Closer to 1 is better fit.\n",
    "\n",
    "If R² < 0.5, consider:\n",
    "    - Adding more relevant features\n",
    "    - Feature engineering (e.g., log transformation, polynomial features)\n",
    "    - Tuning hyperparameters (e.g., learning rate, max_depth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE_LR: 23943.354628825597, MSE_LR: 599434165.9411061\n",
      "R²_LR Score: -0.56\n",
      "      Actual     Predicted\n",
      "0   35567.26  53510.007902\n",
      "17    109.61  27115.273267\n",
      "15  39163.76  14934.566004\n",
      "1   44512.46  12848.926244\n",
      "8     160.80  19036.434223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "df_new[\"Asset_Types\"] = label_encoder.fit_transform(df_new[\"Asset_Types\"])  # Convert asset type to numbers\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df_new[[\"Investment_Amounts\", \"Asset_Types\", \"Year\", \"Month\", \"Quarter\"]]\n",
    "y = df_new[\"Current_Values\"]\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a regression model\n",
    "LR_model = LinearRegression()\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "y_pred = LR_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_LR = mean_absolute_error(y_test, y_pred)\n",
    "mse_LR = mean_squared_error(y_test, y_pred)\n",
    "r2_LR = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE_LR: {mae_LR}, MSE_LR: {mse_LR}\")\n",
    "print(f\"R²_LR Score: {r2_LR:.2f}\")  # Closer to 1 means better fit\n",
    "\n",
    "\n",
    "# Display predicted vs actual values\n",
    "LR_results = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
    "print(LR_results.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "R² = -0.56. R² measures the proportion of the variance in the dependent variable that is predictable from the independent variables. An R² score ranges from 0 to 1 (for a good fit), and negative values indicate that your model is worse than a simple mean-based model. In this case, an R² of -0.56 suggests that the model is doing poorly and is less accurate than just predicting the average of the target variable. It indicates a significant misfit and implies that your model is not capturing the underlying trends in the data.\n",
    "\n",
    "The negative R² value suggests the model’s predictions are worse than predicting the average of the target variable, indicating that the chosen features may not be suitable, or the model is not well-specified.\n",
    "\n",
    "\n",
    "MAE = 23943 means, on average, the model's predictions are off by $23943.\n",
    "\n",
    "MSE = 599434165 is large due to squared differences but helps compare models.this suggests that there may be some significant outliers or large deviations in your model’s predictions, given the high number\n",
    "\n",
    "This model is not performing well overall, as shown by the high MAE and MSE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future Predictions\n",
    "Let's say we want to predict the future investment value for:\n",
    "\n",
    "Investment Amount = $20,000\n",
    "Asset Type = \"Stocks\"\n",
    "Investment Date = March 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Future Investment Value: $41,610.29\n"
     ]
    }
   ],
   "source": [
    "# # Sample data to fit the encoder\n",
    "# asset_types = [\"Stocks\", \"Bonds\", \"Real Estate\"]  # Your list of asset types\n",
    "\n",
    "\n",
    "# # Create the LabelEncoder and fit it\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(asset_types)\n",
    "\n",
    "# Encode asset type\n",
    "asset_type_encoded = label_encoder.fit_transform([\"Stocks\"])[0]\n",
    "\n",
    "# Define input for prediction\n",
    "future_data = pd.DataFrame([[20000, asset_type_encoded, 2025, 3, 1]], \n",
    "                           columns=[\"Investment_Amounts\", \"Asset_Types\", \"Year\", \"Month\", \"Quarter\"])\n",
    "\n",
    "# Predict future value\n",
    "future_value = LR_model.predict(future_data)\n",
    "print(f\"Predicted Future Investment Value: ${future_value[0]:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model - Random Forest Classifier\n",
    "If we want to predict whether an investment will be profitable or not (i.e., classification problem), we need different metrics:\n",
    "\n",
    "Accuracy = (Correct Predictions) / (Total Predictions): Overall percentage of correct predictions. Works well if classes are balanced.\n",
    "\n",
    "Precision = TP / (TP + FP) → How many predicted profitable investments were truly profitable?: Out of all predicted positives, how many were actually positive? Important if false positives are costly.\n",
    "\n",
    "Recall (Sensitivity) = TP / (TP + FN) → How well did we find all profitable investments?: Out of all actual positives, how many did we correctly identify? Important when missing positives is risky.\n",
    "\n",
    "F1-score = Harmonic mean of Precision and Recall. Best for imbalanced datasets.\n",
    "\n",
    "AUC-ROC Score = Measures model discrimination between profitable vs. non-profitable investments.:Measures how well the model distinguishes between classes (1 vs. 0). Closer to 1 is better.\n",
    "\n",
    "\n",
    "If Recall is low, improve it by:\n",
    "    - Increasing max_depth in XGBoost\n",
    "    - Adjusting class weights (e.g., scale_pos_weight)\n",
    "    - Using SMOTE (Synthetic Minority Over-sampling Technique) for imbalanced datasets\n",
    "\n",
    "\n",
    "Convert Regression to Classification\n",
    "Let's classify investments into Profitable (1) or Not Profitable (0) based on ROI (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_RF: 0.60\n",
      "Precision_RF: 0.50\n",
      "Recall_RF: 0.50\n",
      "F1 Score_RF: 0.50\n",
      "AUC-ROC_RF: 0.67\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#import xgboost as xgb\n",
    "\n",
    "# Create a new binary target: 1 if ROI > 0, else 0\n",
    "df_new[\"Profitable\"] = np.where(df_new[\"ROI (%)\"] > 0, 1, 0)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X_RF_class = df_new[[\"Investment_Amounts\", \"Asset_Types\", \"Year\", \"Month\", \"Quarter\"]]\n",
    "y_RF_class = df_new[\"Profitable\"]\n",
    "\n",
    "# Split data\n",
    "X_train_RF_class, X_test_RF_class, y_train_RF_class, y_test_RF_class = train_test_split(X_RF_class, y_RF_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a classification model\n",
    "clf_RF = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_RF.fit(X_train_RF_class, y_train_RF_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_RF_class = clf_RF.predict(X_test_RF_class)\n",
    "y_pred_RF_prob = clf_RF.predict_proba(X_test_RF_class)[:, 1]  # Probability scores for ROC AUC\n",
    "\n",
    "# Compute classification metrics\n",
    "accuracy_RF = accuracy_score(y_test_RF_class, y_pred_RF_class)\n",
    "precision_RF = precision_score(y_test_RF_class, y_pred_RF_class)\n",
    "recall_RF = recall_score(y_test_RF_class, y_pred_RF_class)\n",
    "f1_RF = f1_score(y_test_RF_class, y_pred_RF_class)\n",
    "roc_auc_RF = roc_auc_score(y_test_RF_class, y_pred_RF_prob)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy_RF: {accuracy_RF:.2f}\")\n",
    "print(f\"Precision_RF: {precision_RF:.2f}\")\n",
    "print(f\"Recall_RF: {recall_RF:.2f}\")\n",
    "print(f\"F1 Score_RF: {f1_RF:.2f}\")\n",
    "print(f\"AUC-ROC_RF: {roc_auc_RF:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "Accuracy = 60% → The model classifies 60% of investments correctly.\n",
    "Precision = 50% → 50% of predicted profitable investments were truly profitable.\n",
    "Recall = 50% → The model correctly identifies 50% of actual profitable investments.\n",
    "F1 Score = 50% → medium balance between precision and recall.\n",
    "AUC-ROC = 0.67 → The model has fair discrimination ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is a powerful and efficient model for both regression and classification tasks.\n",
    "Need to install: pip install xgboost\n",
    "# XGBoost Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE_XGB: 4574.65\n",
      "MSE_XGB: 61766400.33\n",
      "R²_XGB Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define features (X) and target (y)\n",
    "X_xgb_reg = df_new.drop(columns=[\"Customer_ID\", \"Investment_Date\", \"Current_Values\"])\n",
    "y_xgb_reg = df_new[\"Current_Values\"]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_xgb_reg, X_test_xgb_reg, y_train_xgb_reg, y_test_xgb_reg = train_test_split(X_xgb_reg, y_xgb_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Regressor\n",
    "xgb_regressor = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_regressor.fit(X_train_xgb_reg, y_train_xgb_reg)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_reg = xgb_regressor.predict(X_test_xgb_reg)\n",
    "\n",
    "# Regression Metrics\n",
    "mae_xgb_reg = mean_absolute_error(y_test_xgb_reg, y_pred_xgb_reg)\n",
    "mse_xgb_reg = mean_squared_error(y_test_xgb_reg, y_pred_xgb_reg)\n",
    "r2_xgb_reg = r2_score(y_test_xgb_reg, y_pred_xgb_reg)\n",
    "\n",
    "print(f\"MAE_XGB: {mae_xgb_reg:.2f}\")\n",
    "print(f\"MSE_XGB: {mse_xgb_reg:.2f}\")\n",
    "print(f\"R²_XGB Score: {r2_xgb_reg:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "R² = 0.84 means the model explains 84% of the variance in Current_Values, which is good.\n",
    "MAE = 4574.65 means, on average, the model's predictions are off by $4574.65.\n",
    "MSE = 61766400.33 is large due to squared differences but helps compare models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classification Modle (Predicting Profitable Investments)\n",
    "If we want to predict whether an investment is Profitable (1) or Not (0):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_xgb: 0.60\n",
      "Precision_xgb: 0.00\n",
      "Recall_xgb: 0.00\n",
      "F1_xgb Score: 0.00\n",
      "AUC-ROC_xgb: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JalpaZenisha\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create binary target: 1 if ROI > 0, else 0\n",
    "df_new[\"Profitable\"] = np.where(df_new[\"Current_Values\"] > df_new[\"Investment_Amounts\"], 1, 0)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X_xgb_class = df_new.drop(columns=[\"Customer_ID\", \"Investment_Date\", \"Current_Values\", \"Profitable\"])\n",
    "y_xgb_class = df_new[\"Profitable\"]\n",
    "\n",
    "# Split data\n",
    "X_train_xgb_class, X_test_xgb_class, y_train_xgb_class, y_test_xgb_class = train_test_split(X_xgb_class, y_xgb_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "#xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=50, random_state=42)\n",
    "\n",
    "xgb_classifier.fit(X_train_xgb_class, y_train_xgb_class)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb_class = xgb_classifier.predict(X_test_xgb_class)\n",
    "y_pred_xgb_prob = xgb_classifier.predict_proba(X_test_xgb_class)[:, 1]  # Probability scores for ROC AUC\n",
    "\n",
    "# Classification Metrics\n",
    "accuracy_xgb = accuracy_score(y_test_xgb_class, y_pred_xgb_class)\n",
    "precision_xgb = precision_score(y_test_xgb_class, y_pred_xgb_class)\n",
    "recall_xgb = recall_score(y_test_xgb_class, y_pred_xgb_class)\n",
    "f1_xgb = f1_score(y_test_xgb_class, y_pred_xgb_class)\n",
    "roc_auc_xgb = roc_auc_score(y_test_xgb_class, y_pred_xgb_prob)\n",
    "\n",
    "print(f\"Accuracy_xgb: {accuracy_xgb:.2f}\")\n",
    "print(f\"Precision_xgb: {precision_xgb:.2f}\")\n",
    "print(f\"Recall_xgb: {recall_xgb:.2f}\")\n",
    "print(f\"F1_xgb Score: {f1_xgb:.2f}\")\n",
    "print(f\"AUC-ROC_xgb: {roc_auc_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.60\n",
    "This means the model is correctly predicting 60% of the cases. While this is decent for a baseline.\n",
    "\n",
    "Precision: 0.00\n",
    "Precision measures the proportion of positive predictions that were actually correct. A precision of 0.00 means that when the model predicts a positive outcome, it is always wrong. This suggests that the model might not be predicting positive outcomes at all, or it could be severely imbalanced in its predictions.\n",
    "\n",
    "Recall: 0.00\n",
    "Recall measures the proportion of actual positive cases that the model correctly identifies. A recall of 0.00 indicates that the model is not identifying any of the true positive cases.\n",
    "\n",
    "F1 Score: 0.00\n",
    "The F1 score is the harmonic mean of precision and recall. Since both precision and recall are 0.00, the F1 score is also 0.00, meaning the model is performing very poorly in terms of its positive class predictions.\n",
    "\n",
    "AUC-ROC: 0.50\n",
    "AUC-ROC is a measure of the model's ability to distinguish between positive and negative classes. A value of 0.50 means the model is performing no better than random chance in distinguishing between the classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Reasons and Solutions:\n",
    "\n",
    "Class Imbalance: If you are working with imbalanced classes (for example, many more negatives than positives), the model may predict only the majority class. You could address this by:\n",
    "\n",
    "Using techniques like SMOTE (Synthetic Minority Over-sampling Technique) or undersampling the majority class.\n",
    "Adjusting class weights in the XGBoost model to penalize misclassifying the minority class more heavily.\n",
    "Model Configuration or Hyperparameters:\n",
    "\n",
    "The hyperparameters might need adjustment. For example, you may want to tune parameters like max_depth, learning_rate, n_estimators, and scale_pos_weight to improve performance.\n",
    "Data Quality or Feature Engineering:\n",
    "\n",
    "Ensure that your features are well-processed and relevant to the prediction task. You might need to improve feature engineering, perform feature selection, or handle missing data more effectively.\n",
    "Threshold Adjustment:\n",
    "\n",
    "The default threshold for classification might not be optimal. You can try adjusting the threshold for classification, which might help balance precision and recall.\n",
    "Model Evaluation:\n",
    "\n",
    "Check the confusion matrix to better understand where the model is making errors. This can provide insight into the specific issues (e.g., misclassifying all positives as negatives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning (Using Grid Search)\n",
    "To further optimize the XGBoost model, we can perform Grid Search to find the best parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Tuned Model Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Perform Grid Search for Classification\n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(random_state=42), param_grid, cv=3, scoring=\"accuracy\", verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_xgb_class, y_train_xgb_class)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train model with best parameters\n",
    "best_xgb_class = grid_search.best_estimator_\n",
    "y_pred_best_xgb_class = best_xgb_class.predict(X_test_xgb_class)\n",
    "\n",
    "# Evaluate best model\n",
    "accuracy_best = accuracy_score(y_test_xgb_class, y_pred_best_xgb_class)\n",
    "print(f\"Tuned Model Accuracy: {accuracy_best:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "Now that the model is trained, we need to save it and deploy it for real-world use.\n",
    "\n",
    "1️. Save and Load the Model\n",
    "To use the model later, save it as a .json or .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open(\"xgboost_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(xgb_classifier, file)\n",
    "\n",
    "# Load the model\n",
    "with open(\"xgboost_model.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Use the loaded model for predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2️. Deploy with a Simple Flask API\n",
    "\n",
    "create an API to serve predictions using Flask.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a app.py file:\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"xgboost_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()  # Expecting JSON input\n",
    "    df = pd.DataFrame(data)  # Convert to DataFrame\n",
    "    \n",
    "    prediction = model.predict(df)\n",
    "    \n",
    "    return jsonify({'prediction': prediction.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 Run the API:\n",
    "\n",
    "python app.py\n",
    "\n",
    "# This will create an API endpoint (/predict) that takes JSON input and returns predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deploy Using FastAPI (Optional)\n",
    "If you need a faster API:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi uvicorn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create main.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "with open(\"xgboost_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(data: dict):\n",
    "    df = pd.DataFrame([data])\n",
    "    prediction = model.predict(df)\n",
    "    return {\"prediction\": prediction.tolist()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvicorn main:app --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then test with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X 'POST' 'http://127.0.0.1:8000/predict' -H 'Content-Type: application/json' -d '{\"Investment_Amounts\": 5000, \"Year\": 2024, \"Month\": 2, \"Quarter\": 1}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "1️⃣ Optimize Feature Engineering (Try different transformations like scaling, log transformations, or PCA)\n",
    "2️⃣ Deploy on Cloud (Use AWS Lambda, Google Cloud Run, or Azure Functions)\n",
    "3️⃣ Automate Model Retraining (Use a scheduled job to update predictions)\n",
    "4️⃣ Integrate with Tableau (Expose API for real-time updates in Tableau dashboards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying XGBoost Model on the Cloud (AWS, GCP, or Azure)\n",
    "To integrate XGBoost model with Tableau, we need to deploy it on the cloud so that Tableau can access predictions via an API. Below are the steps for deploying on AWS, but the process is similar for GCP or Azure.\n",
    "\n",
    "**Step 1: Choose a Cloud Service**\n",
    "\n",
    "- AWS Lambda + API Gateway (Serverless, cost-effective)\n",
    "- AWS EC2 (More control, but requires manual setup)\n",
    "- Google Cloud Run (Scalable serverless option)\n",
    "- Azure Functions (Similar to AWS Lambda)\n",
    "\n",
    "For simplicity, let’s deploy on AWS using Flask and EC2. \n",
    "\n",
    "**Step 2: Prepare Your XGBoost Model**\n",
    "Convert your trained XGBoost model into a deployable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "with open(\"xgboost_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(xgb_classifier, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Set Up an AWS EC2 Instance**\n",
    "\n",
    "1️  Log in to AWS Console\n",
    "\n",
    "2️  Go to EC2 Dashboard → Click Launch Instance\n",
    "\n",
    "3️  Choose Ubuntu 22.04 as OS\n",
    "\n",
    "4️  Select t2.micro (Free-tier eligible)\n",
    "\n",
    "5️  Configure Security Group:\n",
    "\n",
    "    - Allow HTTP (port 80) and Custom TCP (port 5000)\n",
    "    - Allow SSH (port 22) for remote access\n",
    "\n",
    "6️  Click Launch, then Connect to Instance via SSH:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh -i \"your-key.pem\" ubuntu@your-ec2-public-ip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Install Required Libraries**\n",
    "\n",
    "Once inside your EC2 instance, install dependencies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt update && sudo apt upgrade -y\n",
    "sudo apt install python3-pip -y\n",
    "pip3 install flask pandas xgboost pickle-mixin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Deploy Flask API**\n",
    "\n",
    "Create a new file app.py and paste this code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained model\n",
    "with open(\"xgboost_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()  # Expecting JSON input\n",
    "    df = pd.DataFrame(data)  # Convert to DataFrame\n",
    "    prediction = model.predict(df)\n",
    "    return jsonify({'prediction': prediction.tolist()})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Start API Server**\n",
    "Run the Flask app:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 app.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your API is now running on  http://your-ec2-public-ip:5000/predict.\n",
    "\n",
    "**Step 7: Test the API**\n",
    "\n",
    "On your local machine, send a request using Postman or curl:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST \"http://your-ec2-public-ip:5000/predict\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '[{\"Investment_Amount\": 5000, \"Year\": 2024, \"Month\": 2, \"Quarter\": 1}]'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Response:\n",
    "\n",
    "{\"prediction\": [1]}\n",
    "\n",
    "This means Investment_Amount = $5000 is predicted to be Profitable (1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Connect API to Tableau**\n",
    "Now, integrate the API into Tableau.\n",
    "\n",
    "In Tableau\n",
    "- Open Tableau Desktop\n",
    "- Go to Data Source → Select \"Web Data Connector\"\n",
    "- Use a simple Python Flask API connector or a Tableau Web Data Connector (WDC)\n",
    "- Fetch predictions dynamically and display in a Tableau Dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting Your XGBoost API to Tableau via Web Data Connector (WDC)\n",
    "To display your XGBoost model’s predictions in Tableau, we need to create a Web Data Connector (WDC) that fetches data from the deployed Flask API on AWS.\n",
    "\n",
    "🔹 Step 1: Install Tableau Web Data Connector SDK\n",
    "Since Tableau does not natively support REST APIs, we need a WDC (Web Data Connector) to interact with the Flask API.\n",
    "\n",
    "1️⃣ Install Tableau WDC SDK on your local machine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npm install -g tableauwdc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2️⃣ Clone the Web Data Connector SDK:\n",
    "\n",
    "git clone https://github.com/tableau/webdataconnector.git\n",
    "cd webdataconnector/Examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Create a New Web Data Connector (WDC)**\n",
    "Inside the webdataconnector/Examples folder, create a new file flask_wdc.html.\n",
    "\n",
    "flask_wdc.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>XGBoost Predictions WDC</title>\n",
    "    <script src=\"https://connectors.tableau.com/libs/tableauwdc-2.3.latest.js\"></script>\n",
    "    <script>\n",
    "        (function() {\n",
    "            var myConnector = tableau.makeConnector();\n",
    "\n",
    "            myConnector.getSchema = function(schemaCallback) {\n",
    "                var cols = [\n",
    "                    { id: \"Investment_Amount\", alias: \"Investment Amount ($)\", dataType: tableau.dataTypeEnum.float },\n",
    "                    { id: \"Year\", alias: \"Year\", dataType: tableau.dataTypeEnum.int },\n",
    "                    { id: \"Month\", alias: \"Month\", dataType: tableau.dataTypeEnum.int },\n",
    "                    { id: \"Quarter\", alias: \"Quarter\", dataType: tableau.dataTypeEnum.int },\n",
    "                    { id: \"Prediction\", alias: \"Predicted Outcome\", dataType: tableau.dataTypeEnum.string }\n",
    "                ];\n",
    "\n",
    "                var tableSchema = {\n",
    "                    id: \"investmentPredictions\",\n",
    "                    alias: \"Predictions from XGBoost Model\",\n",
    "                    columns: cols\n",
    "                };\n",
    "\n",
    "                schemaCallback([tableSchema]);\n",
    "            };\n",
    "\n",
    "            myConnector.getData = function(table, doneCallback) {\n",
    "                var apiUrl = \"http://your-ec2-public-ip:5000/predict\";\n",
    "\n",
    "                fetch(apiUrl, {\n",
    "                    method: \"POST\",\n",
    "                    headers: {\n",
    "                        \"Content-Type\": \"application/json\"\n",
    "                    },\n",
    "                    body: JSON.stringify([\n",
    "                        {\"Investment_Amount\": 10000, \"Year\": 2024, \"Month\": 2, \"Quarter\": 1},\n",
    "                        {\"Investment_Amount\": 20000, \"Year\": 2024, \"Month\": 3, \"Quarter\": 1}\n",
    "                    ])\n",
    "                })\n",
    "                .then(response => response.json())\n",
    "                .then(data => {\n",
    "                    var tableData = [];\n",
    "                    for (var i = 0; i < data.prediction.length; i++) {\n",
    "                        tableData.push({\n",
    "                            \"Investment_Amount\": [10000, 20000][i],\n",
    "                            \"Year\": 2024,\n",
    "                            \"Month\": [2, 3][i],\n",
    "                            \"Quarter\": 1,\n",
    "                            \"Prediction\": data.prediction[i] === 1 ? \"Profitable\" : \"Risky\"\n",
    "                        });\n",
    "                    }\n",
    "                    table.appendRows(tableData);\n",
    "                    doneCallback();\n",
    "                });\n",
    "            };\n",
    "\n",
    "            tableau.registerConnector(myConnector);\n",
    "\n",
    "            document.querySelector(\"#submitButton\").addEventListener(\"click\", function() {\n",
    "                tableau.connectionName = \"XGBoost Predictions Data\";\n",
    "                tableau.submit();\n",
    "            });\n",
    "        })();\n",
    "    </script>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>XGBoost Investment Predictions</h1>\n",
    "    <button id=\"submitButton\">Get Data</button>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Host WDC on a Local Web Server**\n",
    "Since Tableau cannot directly open local .html files, we need to serve it using a simple Python HTTP server.\n",
    "\n",
    "1️⃣ Navigate to the directory where flask_wdc.html is located:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /path/to/webdataconnector/Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ Start a local web server:\n",
    "\n",
    "python3 -m http.server 8000\n",
    "\n",
    "3️⃣ Your WDC is now available at:\n",
    "\n",
    " http://localhost:8000/flask_wdc.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Connect to Tableau**\n",
    "\n",
    "1️⃣ Open Tableau Desktop\n",
    "\n",
    "2️⃣ Go to \"Connect\" → Select \"Web Data Connector\"\n",
    "\n",
    "3️⃣ Enter the URL:\n",
    "\n",
    "http://localhost:8000/flask_wdc.html\n",
    "\n",
    "4️⃣ Click \"Get Data\" and wait for predictions to load\n",
    "\n",
    "5️⃣ Click \"Update Extract\" and then go to Sheet 1 to create visualizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Deploy WDC to AWS (Optional)**\n",
    "To access the WDC remotely, deploy it to AWS S3 or an EC2 instance.\n",
    "\n",
    "1️⃣ Copy flask_wdc.html to your AWS EC2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scp -i \"your-key.pem\" flask_wdc.html ubuntu@your-ec2-public-ip:/var/www/html/\n",
    "\n",
    "# 2️⃣ Access it in Tableau using:\n",
    "\n",
    "http://your-ec2-public-ip/flask_wdc.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next Steps:**\n",
    "- Fine-tune XGBoost model\n",
    "- Deploy on AWS Lambda (for serverless API)\n",
    "- Automate API requests with Tableau Extract Refresh\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
